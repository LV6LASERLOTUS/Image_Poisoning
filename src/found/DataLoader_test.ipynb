{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8350a0b-2f01-481c-a0b1-d9f8422032d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca0cf71-5087-4263-967f-6de74b6c3b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/packages/envs/pytorch-gpu-2.1.0-cuda-12.1/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_RKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn,optim,Tensor\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3af053b7-b374-40f6-a449-845a45265370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to models\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from models.VGG13 import VGG13\n",
    "from models.DataLoader import FaceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e9877e-98d1-4dd2-bd27-7a3eb355d682",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "705f3589-8024-483e-ad50-472dc40a4a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dataset: 5000\n",
      "Train                  : 3500\n",
      "Attack                 : 500\n",
      "Test                   : 1000\n"
     ]
    }
   ],
   "source": [
    "# Training Variable\n",
    "\n",
    "\n",
    "ROOT_PATH=\"/home/ychien13/my_github/CSE467_Privacy/Image_Poisoning/data/raw/Images\"\n",
    "IN_CHANNELS=3\n",
    "OUT_CHANNELS=3\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE=1e-4\n",
    "EPOCHS=20\n",
    "\n",
    "# Check is nvidia GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=(67.3686, 52.9727, 44.3268),std=(42.2854, 35.1020, 32.3488)),\n",
    "    transforms.Resize((224,224),antialias=True)\n",
    "])\n",
    "\n",
    "# Initializing Datasets\n",
    "dataset = FaceDataset(ROOT_PATH,transform)\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "\n",
    "train_data,attack_data, test_data = random_split(dataset,[0.7,0.1,0.2],generator=generator)\n",
    "\n",
    "print('Total number of dataset:',len(dataset))\n",
    "print('Train                  :',len(train_data))\n",
    "print('Attack                 :', len(attack_data))\n",
    "print('Test                   :', len(test_data))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True, drop_last=True, generator=generator)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, generator=generator)\n",
    "\n",
    "\n",
    "# Setting up the Model\n",
    "\n",
    "model = VGG13(IN_CHANNELS,OUT_CHANNELS).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da30a28d-63d4-432a-a7b0-04ede4ce2f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e21bef77-b4cb-44ae-b238-97f9c9827986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputs, targets = next(iter(train_loader)) \n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    for idx, (inputs, targets) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,targets)\n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        correct+=(outputs.argmax(dim=1) == targets).sum().item()\n",
    "        total+=targets.size(0)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}] | {correct}/{total} | Accuracy: {correct/total:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46c2be-b6f9-4c6d-bd98-a5c4f27d70d0",
   "metadata": {},
   "source": [
    "### Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf356a6-d261-46a9-b3b5-45e7714a6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG13(IN_CHANNELS,OUT_CHANNELS).to(device)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True, drop_last=True)\n",
    "\n",
    "inputs, targets = next(iter(train_loader)) \n",
    "\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "\n",
    "# Get the base feature vector\n",
    "base_vector = model.extract_features(inputs)\n",
    "\n",
    "# calculate disruptor from gaussian noie\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c1880-7a97-4416-ac82-1a549af7b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24951f81-ad82-45d9-b1e5-7c3e30028fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f162eb8-8577-4084-9d0d-cad5261a4092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
