{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8350a0b-2f01-481c-a0b1-d9f8422032d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ca0cf71-5087-4263-967f-6de74b6c3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a5430-9298-421f-be32-34684cfdb961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671ad8bf-ec27-44f1-b574-6145938b35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures={\n",
    "    'object_1' : \"/home/ychien13/my_github/CSE467_Privacy/Image_Poisoning-/data/raw/Images/Objects/object_1.jpg\",\n",
    "    'female_1' : \"/home/ychien13/my_github/CSE467_Privacy/Image_Poisoning-/data/raw/Images/female_faces/female_2.jpg\",\n",
    "    'male_1' : \"/home/ychien13/my_github/CSE467_Privacy/Image_Poisoning-/data/raw/Images/male_faces/male_3.jpg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "405ff059-25b5-4c56-81d4-dc6156698f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 940, 3)\n",
      "(650, 531, 3)\n",
      "(627, 940, 3)\n"
     ]
    }
   ],
   "source": [
    "for keys in pictures.keys():\n",
    "    img = cv.imread(pictures[keys])\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15bc13c1-e1d9-4dac-afe2-8dd0577be6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame, phase: str=\"test\", is_resize: bool=False):\n",
    "        ...\n",
    "        \n",
    "    def load_img(self, file_path):\n",
    "        ...\n",
    "    \n",
    "    def normalize(self, data: np.ndarray):\n",
    "        ...\n",
    "    def resize(self, data: np.ndarray):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1a0dcab-450c-4a6a-b957-e04ca6f3488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A double convolutional Layer with 3x3, ReLU, and optional MaxPooling\n",
    "    \n",
    "    includes a foward method to pass argument forward\n",
    "    \n",
    "    Attributes:\n",
    "    \n",
    "        in_channels (int): The dimensin of the img \n",
    "        out_channels (int): The number of classification\n",
    "        use_pooling (bool): Whether or not to use pooling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels:int, out_channels:int, use_pooling:bool=True):\n",
    "        super().__init__()\n",
    "        self.conv_op=nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        if use_pooling:\n",
    "            self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "\n",
    "        conv = self.conv_op(x)\n",
    "        pooling = self.pool(conv)\n",
    "        \n",
    "        return pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeaa7615-e6c4-4b65-ba0e-0e3fecaad1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG13(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels:int,num_channels:int):\n",
    "        super().__init__()\n",
    "\n",
    "        # 10 layers of Convolution\n",
    "        self.block1 = DoubleConv(in_channels,64)\n",
    "        self.block2 = DoubleConv(64,128)\n",
    "        self.block3 = DoubleConv(128,256)\n",
    "        self.block4 = DoubleConv(256,512)\n",
    "        self.block5 = DoubleConv(512,512)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(7*7*512,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,num_channels)\n",
    "        ) \n",
    "\n",
    "    def extract_features(self,x)->Tensor:\n",
    "        \n",
    "        down1 = self.block1(x)\n",
    "        down2 = self.block2(down1)\n",
    "        down3 = self.block3(down2)\n",
    "        down4 = self.block4(down3)\n",
    "        down5 = self.block5(down4)\n",
    "        \n",
    "        flatten_features = down5.flatten(start_dim=1)\n",
    "\n",
    "        # Returns a tensor (7*512*512)\n",
    "        return flatten_features\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        flatten_x:torch.tensor = self.extract_features(x)\n",
    "        output = self.fc(flatten_x)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def train(self):\n",
    "        ...\n",
    "        \n",
    "    def evaluate(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c4be96e-53dd-41c4-a076-a091bee72c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoubleConv(\n",
      "  (conv_op): Sequential(\n",
      "    (0): Conv2d(224, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(244, 244, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    double_conv = DoubleConv(224,244)\n",
    "    print(double_conv)\n",
    "    \n",
    "    img = torch.randn(1, 3, 224, 224)\n",
    "    model = VGG13(in_channels=3,num_channels=3)\n",
    "    output = model.extract_features(img)\n",
    "    print(output.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "705f3589-8024-483e-ad50-472dc40a4a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25088])\n"
     ]
    }
   ],
   "source": [
    "# batch of 10 images, 3x32x32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62b18b-c3a8-41af-bea7-c12048d9dfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d75df-027f-4c04-9343-8bb28d465499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b101e3-834d-4585-8539-f698cba7c921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32e311-5877-40cb-90d5-1d40f39cf71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5458e9-84ac-43f5-a9d4-567d997afec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b5870-fc35-4a9e-bcaa-ec3623bd77d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.1.0-cuda-12.1",
   "language": "python",
   "name": "pytorch-gpu-2.1.0-cuda-12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
